# Sentence Segmentation Project

This repository contains scripts and notebooks for sentence segmentation tasks, focusing on training and evaluating a Decision Tree classifier and comparing it with large language models (LLMs).

## Overview

The notebooks are ready to run on Google Colab with Google Drive mounted.

The scripts can be run locally or in any Python environment with the required packages.

### Repository Structure

**Notebooks** – Jupyter notebooks ready to run on Google Colab.

**Scripts** – Python scripts that can be run locally or on any Python environment.

**Data** – Input and output data files, including manual files. These files are used by both notebooks and scripts.


# Running the notebooks on Google Colab

The notebooks are prepared to be run on Google Colab with Google Drive mounted.

```python
from google.colab import drive
drive.mount('/content/drive') 
```

**Data files:** 
Before running a notebook, upload the required input files (found in the data/ folder of this repo) into the /content directory of your Colab session.
This ensures the notebook can access the data correctly.

**Manual Files** 
Several important files were created manually or semi-manually (i.e., with some automated methods plus manual revision) and are not generated by scripts in this repository. They are necessary for training and evaluation, those files are:

- 'output_corpus_no_ricette.txt': Cleaned corpus without a part of the recipe-like sections, used to build the training DataFrame. We made the choice of taking off the recipes from the due parole corpus because after dividing the texts of the dueparole corpus in sentences we noticed that the spacy sentenizer wasn't performing well on a part of the recipe's texts of our corpus, especially the section "Cosa serve" where the ingredients were elencati in un elenco puntato.
The file output_corpus_no_ricette.txt was manually created from the file output_corpus_in_frasi.txt, that is the output of the script called "corpus_in_frasi_dueparole" that you can find on the preprocessing folder. The file output_corpus_no_ricette.txt is used in the script dataframe_dueparole.py to create the dataframe to train the decision Tree.

- corpus_in_frasi_anfass_tagliato_perdecision.txt: Derived corpus excluding sentences modified by the LLM model, to ensure fair evaluation comparability. This txt was manually created from the file 

Final evaluation files: frasi_semplificate_gemma_2_9b_it_anfass2_tagliato.txt, /content/frasi_semplificate_gemma_2_9b_it_anfass1_tagliato.txt, frasi_segmentate_per_evaluation_tagliato.txt. These were filtered to exclude sentences modified by the LLM and used in the final evaluation.


## Running the scripts locally

The Python scripts in this repository can be run in any Python environment.

**Setup Environment (Local Linux)**
If you want to run the scripts locally on a Linux machine, follow these steps:

1. Create and activate a Python virtual environment:
```python
python -m venv env
source env/bin/activate
```
2. Install the required packages:
```python
pip install -r requirements.txt
```
3. Download the spaCy Italian language model:
```python
python -m spacy download it_core_news_sm
```


#### How to Run the Project

Running the scripts (local or remote environment)
To reproduce the full pipeline, run the scripts in the following order:

1. **Preprocessing script**
These scripts are stored in the 'preprocessing' folder.
They prepare and clean the corpus files, by dividing the two corpora in sentences and generate the DataFrame used for training the decision tree models.

2. **Decision Tree scripts**
These scripts are stored in the 'decision_tree' folder.
They train and evaluate a Decision Tree classifier on the 3 different preprocessed DataFrame, prepared with the scripts of the 'preprocessing' folder.
generate metrics and confusion matrices

3. **LLM script**
Perform the task of sentence segmentation using an LLM, the model Gemma 9 2b it tested on 2 different prompts.

4. **LLM evaluation scripts**
Evaluates the performance of the LLM and compare them with the performances of the Decision Tree Classifier.


