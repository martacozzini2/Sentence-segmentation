{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqbPFlS5bc0j",
        "outputId": "ca33d86f-05b9-457c-a7dd-d55eb15f8167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download it_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Script for processing segmented sentences with spaCy\n",
        "# - Loads sentences with segments marked by <seg>\n",
        "# - Analyzes sentences with spaCy\n",
        "# - Builds a DataFrame with token-level features\n",
        "# - Saves the \"clean\" sentences without <seg> tags in a separate file\n",
        "# ==========================================================\n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "!python -m spacy download it_core_news_sm\n",
        "\n",
        "# Load the spaCy model for Italian\n",
        "nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "# List to collect token-level data\n",
        "tutti_dati = []\n",
        "\n",
        "# List to save the clean sentences (without <seg> tags)\n",
        "frasi_segmentate = []\n",
        "\n",
        "# POS tags of interest\n",
        "pos_tags = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"CCONJ\", \"DET\", \"NUM\", \"PUNCT\", \"PRON\", \"ADP\"]\n",
        "\n",
        "# Function to load numbered sentences from a text file\n",
        "# Each line in the input file should contain a sentence in the format: index<TAB>sentence\n",
        "\n",
        "def carica_frasi_numerate(file_path):\n",
        "    # Opens the file in read mode, using UTF-8 and replacing any invalid characters\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        righe = f.readlines()\n",
        "\n",
        "    frasi = []\n",
        "\n",
        "    # Iterates over each line in the file\n",
        "    for i, riga in enumerate(righe):\n",
        "        riga = riga.strip()  # removes leading/trailing whitespace\n",
        "\n",
        "        # Skips lines that don't contain a tab (not properly formatted)\n",
        "        if \"\\t\" not in riga:\n",
        "            print(f\"[LINE {i+1}] Line ignored (no tab): {riga!r}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Splits the line into two parts: numeric index and sentence\n",
        "            idx, frase = riga.split(\"\\t\", 1)\n",
        "\n",
        "            # Adds a tuple (int index, sentence) to the list\n",
        "            frasi.append((int(idx), frase))\n",
        "        except Exception as e:\n",
        "            # Prints an error if something goes wrong during parsing\n",
        "            print(f\"[LINE {i+1}] Parsing error: {e}\")\n",
        "\n",
        "    return frasi  # Returns the list of (index, sentence) tuples\n",
        "\n",
        "# Specify the input file path\n",
        "file_input = \"/content/corpus_in_frasi_anfass_tagliato_perdecision.txt\"\n",
        "\n",
        "# Load numbered sentences from the file\n",
        "frasi_numerate = carica_frasi_numerate(file_input)\n",
        "\n",
        "# For loop over sentences with <seg> tags\n",
        "for frase_idx, frase_con_seg in frasi_numerate:\n",
        "    # Split the sentence into segments, removing unnecessary spaces\n",
        "    segmenti = [s.strip() for s in frase_con_seg.split(\"<seg>\")]\n",
        "\n",
        "    # Reconstruct the sentence without <seg> tags\n",
        "    frase_pulita = \" \".join(segmenti)\n",
        "\n",
        "    # Apply spaCy to the complete sentence\n",
        "    doc = nlp(frase_pulita)\n",
        "\n",
        "    # Save the clean sentence with its index\n",
        "    frasi_segmentate.append((frase_idx, frase_pulita))\n",
        "\n",
        "    # Tokenize each segment separately\n",
        "    segmenti_tokenizzati = [nlp(seg) for seg in segmenti]\n",
        "\n",
        "    # Compute the length (in tokens) of each segment\n",
        "    lunghezze = [len(seg) for seg in segmenti_tokenizzati]\n",
        "\n",
        "    # Compute the boundaries between segments\n",
        "    confini = set()\n",
        "    offset = 0\n",
        "    for lung in lunghezze[:-1]:  # exclude the last segment\n",
        "        offset += lung\n",
        "        confini.add(offset - 1)  # last token of the segment\n",
        "\n",
        "    # Iterate over tokens in the complete sentence\n",
        "    for i_token, token in enumerate(doc):\n",
        "        if token.text.strip() == \"\":\n",
        "            continue  # Skip empty/whitespace tokens\n",
        "\n",
        "        token_text = token.text\n",
        "        pos = token.pos_\n",
        "\n",
        "        # Normalize some POS categories\n",
        "        if pos == \"AUX\":\n",
        "            pos = \"VERB\"\n",
        "        elif pos == \"SCONJ\":\n",
        "            pos = \"CCONJ\"\n",
        "        elif pos not in pos_tags:\n",
        "            pos = \"ALTRO\"\n",
        "\n",
        "        # Indicates whether the token is at the end of a segment\n",
        "        segmenta = 1 if i_token in confini else 0\n",
        "\n",
        "        # Save relevant information in a list of dictionaries\n",
        "        tutti_dati.append({\n",
        "            \"token\": token_text,\n",
        "            \"segmenta\": segmenta,\n",
        "            \"frase_idx\": frase_idx,\n",
        "            \"frase_len_token\": len(doc),\n",
        "            \"frase_len_char\": len(frase_pulita),\n",
        "            \"token_len_char\": len(token_text),\n",
        "            \"distanza_da_prima_parola\": i_token,\n",
        "            \"pos\": pos\n",
        "        })\n",
        "\n",
        "# Create a DataFrame with all token-level data\n",
        "df = pd.DataFrame(tutti_dati)\n",
        "\n",
        "# Create binary columns for each POS tag\n",
        "for pos_tag in pos_tags:\n",
        "    df[pos_tag] = df['pos'].apply(lambda x: 1 if x == pos_tag else 0)\n",
        "\n",
        "# Reorganize column order in the DataFrame\n",
        "cols_pos = pos_tags\n",
        "other_cols = [col for col in df.columns if col not in cols_pos + [\"frase_idx\", \"token\", \"pos\"]]\n",
        "df = df[[\"frase_idx\", \"token\"] + cols_pos + other_cols]\n",
        "\n",
        "# Save the clean sentences (without <seg>) to file\n",
        "with open(\"corpus_in_frasi_no_seg_anfass_tagliato\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx, frase in frasi_segmentate:\n",
        "        f.write(f\"{idx}\\t{frase}\\n\")\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download(\"corpus_in_frasi_no_seg_anfass_tagliato\")\n",
        "\n",
        "# Save the dataframe to a pickle file\n",
        "import pickle\n",
        "\n",
        "# Save the dataframe to a pickle file (automatically creates the file if it doesn’t exist)\n",
        "with open('anfass_tagliato.pkl', 'wb') as file:\n",
        "    pickle.dump(df, file)  # dump the df dataframe into the opened file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# File path to download\n",
        "file_path = \"/content/anfass_tagliato.pkl\"\n",
        "\n",
        "# Download the file\n",
        "files.download(file_path)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Save the DataFrame as CSV\n",
        "df.to_csv('anfass_tagliato.csv', index=False)  # 'index=False' avoids saving the index as a column\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Path of the file to download\n",
        "file_path_2 = \"/content/anfass_tagliato.csv\"\n",
        "\n",
        "# Download the file\n",
        "files.download(file_path_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "SZMBILiIn91r",
        "outputId": "db9d026c-5b8a-4c88-d8ad-0198b891275a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e763979-a50b-476e-9681-d2b9b0f1330e\", \"corpus_in_frasi_no_seg_anfass_tagliato\", 15919)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8396955-0a41-4e82-a726-25710d501886\", \"anfass_tagliato.pkl\", 372522)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a373e720-15e6-439b-8c83-89b5d9f8548a\", \"anfass_tagliato.csv\", 113936)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}