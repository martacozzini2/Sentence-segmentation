{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# Script for processing segmented sentences with spaCy\n",
        "# - Loads sentences with segments marked by <seg>\n",
        "# - Analyzes sentences with spaCy\n",
        "# - Builds a DataFrame with token-level features\n",
        "# - Saves \"clean\" sentences without <seg> tags to a separate file\n",
        "# We will use the output DataFrame to train and evaluate a Decision Tree\n",
        "# ==========================================================\n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "!python -m spacy download it_core_news_sm\n",
        "\n",
        "#Load the spaCy model for Italian\n",
        "nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "# List to collect token-level data\n",
        "tutti_dati = []\n",
        "\n",
        "# List to save clean sentences (without <seg> tags)\n",
        "frasi_segmentate = []\n",
        "\n",
        "# POS tags of interest\n",
        "pos_tags = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"CCONJ\", \"DET\", \"NUM\", \"PUNCT\", \"PRON\", \"ADP\"]\n",
        "\n",
        "# Function to load numbered sentences from a text file\n",
        "def carica_frasi_numerate(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        righe = f.readlines()\n",
        "\n",
        "    frasi = []\n",
        "\n",
        "  # Iterates all lines in the file one by one\n",
        "    for i, riga in enumerate(righe):\n",
        "        riga = riga.strip()\n",
        "\n",
        "# Skips lines that do not contain a tab (malformed lines)\n",
        "        if \"\\t\" not in riga:\n",
        "            print(f\"[RIGA {i+1}] Riga ignorata (niente tab): {riga!r}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Splits the line into two parts: numeric index and sentence\n",
        "            idx, frase = riga.split(\"\\t\", 1)\n",
        "\n",
        "# Adds a tuple (integer index, sentence) to the list\n",
        "            frasi.append((int(idx), frase))\n",
        "        except Exception as e:\n",
        "            # Prints error if something goes wrong during parsing\n",
        "            print(f\"[RIGA {i+1}] Errore nel parsing: {e}\")\n",
        "\n",
        "    return frasi\n",
        "\n",
        "# Specify the input file path\n",
        "file_input = \"/content/output_corpus_in_no_ricette.txt\"\n",
        "\n",
        "# Loads numbered sentences from the file\n",
        "frasi_numerate = carica_frasi_numerate(file_input)\n",
        "\n",
        "# For loop over sentences with <seg> tags\n",
        "for frase_idx, frase_con_seg in frasi_numerate:\n",
        "    # Splits the sentence into segments, removes unnecessary spaces\n",
        "    segmenti = [s.strip() for s in frase_con_seg.split(\"<seg>\")]\n",
        "\n",
        "    # Rebuilds the sentence without <seg>\n",
        "    frase_pulita = \" \".join(segmenti)\n",
        "\n",
        "    # Applies spaCy to the complete sentence\n",
        "    doc = nlp(frase_pulita)\n",
        "\n",
        "    # Saves the clean sentence with the index\n",
        "    frasi_segmentate.append((frase_idx, frase_pulita))\n",
        "\n",
        "    # Tokenizes each segment separately\n",
        "    segmenti_tokenizzati = [nlp(seg) for seg in segmenti]\n",
        "\n",
        "    # Calculates the length (in tokens) of each segment\n",
        "    lunghezze = [len(seg) for seg in segmenti_tokenizzati]\n",
        "\n",
        "    # Calculates boundaries between segments\n",
        "    confini = set()\n",
        "    offset = 0\n",
        "    for lung in lunghezze[:-1]:\n",
        "        offset += lung\n",
        "        confini.add(offset - 1)\n",
        "\n",
        " # Iterates over tokens in the complete sentence\n",
        "    for i_token, token in enumerate(doc):\n",
        "        if token.text.strip() == \"\":\n",
        "            continue\n",
        "\n",
        "        token_text = token.text\n",
        "        pos = token.pos_\n",
        "\n",
        "        # Normalizes some POS categories\n",
        "        if pos == \"AUX\":\n",
        "            pos = \"VERB\"\n",
        "        elif pos == \"SCONJ\":\n",
        "            pos = \"CCONJ\"\n",
        "        elif pos not in pos_tags:\n",
        "            pos = \"ALTRO\"\n",
        "\n",
        "        # Indicates if the token is at the end of a segment\n",
        "        segmenta = 1 if i_token in confini else 0\n",
        "\n",
        "        # Saves relevant information into a list of dictionaries\n",
        "        tutti_dati.append({\n",
        "            \"token\": token_text,\n",
        "            \"segmenta\": segmenta,\n",
        "            \"frase_idx\": frase_idx,\n",
        "            \"frase_len_token\": len(doc),\n",
        "            \"frase_len_char\": len(frase_pulita),\n",
        "            \"token_len_char\": len(token_text),\n",
        "            \"distanza_da_prima_parola\": i_token,\n",
        "            \"pos\": pos\n",
        "        })\n",
        "\n",
        "# Creates a DataFrame with all token-level data\n",
        "df = pd.DataFrame(tutti_dati)\n",
        "\n",
        "# Creates binary columns for each POS tag\n",
        "for pos_tag in pos_tags:\n",
        "    df[pos_tag] = df['pos'].apply(lambda x: 1 if x == pos_tag else 0)\n",
        "\n",
        "# Reorganizes the column order in the DataFrame\n",
        "cols_pos = pos_tags\n",
        "other_cols = [col for col in df.columns if col not in cols_pos + [\"frase_idx\", \"token\", \"pos\"]]\n",
        "df = df[[\"frase_idx\", \"token\"] + cols_pos + other_cols]\n",
        "\n",
        "# # Saves clean sentences (without <seg>) to a file\n",
        "with open(\"corpus_in_frasi_no_seg\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx, frase in frasi_segmentate:\n",
        "        f.write(f\"{idx}\\t{frase}\\n\")\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download(\"corpus_in_frasi_no_seg\")\n",
        "\n",
        "\n",
        "# Saves the dataframe to a pickle file\n",
        "import pickle\n",
        "\n",
        "# Saves the dataframe to a pickle file (automatically creates the file if it doesn't exist)\n",
        "\n",
        "with open('parole.pkl', 'wb') as file:\n",
        "    pickle.dump(df, file)\n",
        "from google.colab import files\n",
        "\n",
        "file_path = \"/content/parole.pkl\"\n",
        "\n",
        "files.download(file_path)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Saves the DataFrame as CSV\n",
        "df.to_csv('parole.csv', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "file_path = \"/content/parole.csv\"\n",
        "\n",
        "files.download(file_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "USm789DdVNAe",
        "outputId": "204ac4a0-3f9a-400e-f4a6-067a79b6f59c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting it-core-news-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "[RIGA 1220] Riga ignorata (niente tab): '1234'\n",
            "[RIGA 4099] Riga ignorata (niente tab): '4140'\n",
            "[RIGA 4115] Riga ignorata (niente tab): '4156'\n",
            "[RIGA 4262] Riga ignorata (niente tab): '4303'\n",
            "[RIGA 4428] Riga ignorata (niente tab): '4473'\n",
            "[RIGA 4617] Riga ignorata (niente tab): '4670'\n",
            "[RIGA 4667] Riga ignorata (niente tab): '4720'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6a9456b1-c8ef-4803-91a6-59c7c2a151b2\", \"corpus_in_frasi_no_seg\", 450201)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_68400522-95bc-40b9-a1ed-d336d8bc8726\", \"parole.pkl\", 10587210)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab8ef94c-9921-4e7d-bf68-bcf486f82609\", \"parole.csv\", 3395512)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}