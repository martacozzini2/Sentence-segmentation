{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "z01fZFCnbsxE",
        "outputId": "cd498ed0-5ed6-4f6a-db5f-7ff8efbb9fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting it-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7e04ab94-fa70-4973-ade9-c1bd0124ce65\", \"corpus_in_frasi_anfass.txt\", 31762)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Script for segmenting a corpus into sentences using spaCy\n",
        "#\n",
        "# Features:\n",
        "# - Loads a text corpus from file\n",
        "# - Splits the text into blocks using a pattern based on lines separated by ---\n",
        "# - For each block:\n",
        "#     - Replaces line breaks (\\n) with <seg> to indicate internal segments\n",
        "#     - Segments the text into sentences using the Italian spaCy model\n",
        "#     - Removes any <seg> tags at the beginning of sentences\n",
        "# - Saves all numbered sentences (one per line, with index) to an output file\n",
        "# - Automatically downloads the resulting file (for use in Google Colab)\n",
        "# ==========================================================\n",
        "\n",
        "# Download and import the Italian spaCy model\n",
        "!python -m spacy download it_core_news_sm\n",
        "\n",
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load the Italian spaCy language model\n",
        "nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "# Functions\n",
        "\n",
        "# Reads the content of a text file\n",
        "def carica_testo(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        testo = f.read()\n",
        "    return testo\n",
        "\n",
        "# Removes <seg> at the beginning of sentences\n",
        "def rimuovi_seg_inizio_frase(frasi):\n",
        "    frasi_pulite = []\n",
        "    for frase in frasi:\n",
        "        frase_pulita = re.sub(r'^<seg>\\s*', '', frase)\n",
        "        frasi_pulite.append(frase_pulita)\n",
        "    return frasi_pulite\n",
        "\n",
        "# Segments the text into sentences using spaCy\n",
        "def segmenta_testo_spacy(testo):\n",
        "    paragrafi = testo.split(\"\\n\\n\")  # Splits into paragraphs\n",
        "    frasi = []\n",
        "\n",
        "    for p in paragrafi:\n",
        "        p = p.strip()\n",
        "        if not p:\n",
        "            continue\n",
        "        # Replaces \\n with <seg> to mark internal breaks\n",
        "        p = p.replace(\"\\n\", \" <seg> \")\n",
        "        doc = nlp(p)\n",
        "        # Extracts and cleans the segmented sentences\n",
        "        frasi.extend([sent.text.strip() for sent in doc.sents if sent.text.strip()])\n",
        "\n",
        "    # Removes <seg> if it appears at the beginning of the sentence\n",
        "    frasi = rimuovi_seg_inizio_frase(frasi)\n",
        "    return frasi\n",
        "\n",
        "# Splits the text into blocks and segments each block into sentences\n",
        "def segmenta_blocchi(testo):\n",
        "    blocchi = re.split(r\"-{3,} \\d+ .+?\\.txt -{3,}\", testo)  # Splits based on block pattern\n",
        "    blocchi = [b.strip() for b in blocchi if b.strip()]\n",
        "\n",
        "    frasi_totali = []\n",
        "    for blocco in blocchi:\n",
        "        frasi_blocco = segmenta_testo_spacy(blocco)\n",
        "        frasi_totali.extend(frasi_blocco)\n",
        "    return frasi_totali\n",
        "\n",
        "# Saves the numbered sentences to a file\n",
        "def salva_frasi_con_indice(frasi, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, frase in enumerate(frasi, 1):\n",
        "            f.write(f\"{i}\\t{frase}\\n\")\n",
        "\n",
        "\n",
        "input_file = \"/content/corpus_anfass.txt\"\n",
        "output_file = \"corpus_in_frasi_anfass.txt\"\n",
        "\n",
        "# Load the text, segment into sentences, and save\n",
        "testo = carica_testo(input_file)\n",
        "frasi = segmenta_blocchi(testo)\n",
        "salva_frasi_con_indice(frasi, output_file)\n",
        "\n",
        "# Download the segmented file\n",
        "from google.colab import files\n",
        "files.download(\"corpus_in_frasi_anfass.txt\")\n"
      ]
    }
  ]
}